{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\nfrom sklearn.preprocessing import LabelEncoder\nimport os\nimport tensorflow as tf\nfrom tensorflow import keras \n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-09-15T17:27:06.790532Z","iopub.execute_input":"2022-09-15T17:27:06.791076Z","iopub.status.idle":"2022-09-15T17:27:07.079805Z","shell.execute_reply.started":"2022-09-15T17:27:06.791025Z","shell.execute_reply":"2022-09-15T17:27:07.078460Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"AUTOTUNE = tf.data.AUTOTUNE ","metadata":{"execution":{"iopub.status.busy":"2022-09-15T17:27:26.758917Z","iopub.execute_input":"2022-09-15T17:27:26.759349Z","iopub.status.idle":"2022-09-15T17:27:26.765037Z","shell.execute_reply.started":"2022-09-15T17:27:26.759313Z","shell.execute_reply":"2022-09-15T17:27:26.763400Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"DATA_DIR = '../input/jpeg-happywhale-128x128/train_images-128-128/train_images-128-128/'","metadata":{"execution":{"iopub.status.busy":"2022-09-15T17:33:47.613371Z","iopub.execute_input":"2022-09-15T17:33:47.614530Z","iopub.status.idle":"2022-09-15T17:33:47.620321Z","shell.execute_reply.started":"2022-09-15T17:33:47.614470Z","shell.execute_reply":"2022-09-15T17:33:47.619035Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"train_df = pd.read_csv('../input/happy-whale-and-dolphin/train.csv')\ntrain_df.head()","metadata":{"execution":{"iopub.status.busy":"2022-09-15T17:33:47.625509Z","iopub.execute_input":"2022-09-15T17:33:47.625947Z","iopub.status.idle":"2022-09-15T17:33:47.703252Z","shell.execute_reply.started":"2022-09-15T17:33:47.625908Z","shell.execute_reply":"2022-09-15T17:33:47.701887Z"},"trusted":true},"execution_count":17,"outputs":[{"execution_count":17,"output_type":"execute_result","data":{"text/plain":"                image             species individual_id\n0  00021adfb725ed.jpg  melon_headed_whale  cadddb1636b9\n1  000562241d384d.jpg      humpback_whale  1a71fbb72250\n2  0007c33415ce37.jpg  false_killer_whale  60008f293a2b\n3  0007d9bca26a99.jpg  bottlenose_dolphin  4b00fe572063\n4  00087baf5cef7a.jpg      humpback_whale  8e5253662392","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>image</th>\n      <th>species</th>\n      <th>individual_id</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>00021adfb725ed.jpg</td>\n      <td>melon_headed_whale</td>\n      <td>cadddb1636b9</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>000562241d384d.jpg</td>\n      <td>humpback_whale</td>\n      <td>1a71fbb72250</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0007c33415ce37.jpg</td>\n      <td>false_killer_whale</td>\n      <td>60008f293a2b</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0007d9bca26a99.jpg</td>\n      <td>bottlenose_dolphin</td>\n      <td>4b00fe572063</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>00087baf5cef7a.jpg</td>\n      <td>humpback_whale</td>\n      <td>8e5253662392</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"train_df['individual_id'].nunique()","metadata":{"execution":{"iopub.status.busy":"2022-09-15T17:33:47.705573Z","iopub.execute_input":"2022-09-15T17:33:47.705919Z","iopub.status.idle":"2022-09-15T17:33:47.720256Z","shell.execute_reply.started":"2022-09-15T17:33:47.705886Z","shell.execute_reply":"2022-09-15T17:33:47.719084Z"},"trusted":true},"execution_count":18,"outputs":[{"execution_count":18,"output_type":"execute_result","data":{"text/plain":"15587"},"metadata":{}}]},{"cell_type":"code","source":"train_df['species'].nunique()","metadata":{"execution":{"iopub.status.busy":"2022-09-15T17:33:47.721836Z","iopub.execute_input":"2022-09-15T17:33:47.723784Z","iopub.status.idle":"2022-09-15T17:33:47.735460Z","shell.execute_reply.started":"2022-09-15T17:33:47.723739Z","shell.execute_reply":"2022-09-15T17:33:47.734588Z"},"trusted":true},"execution_count":19,"outputs":[{"execution_count":19,"output_type":"execute_result","data":{"text/plain":"30"},"metadata":{}}]},{"cell_type":"code","source":"label_encoder = LabelEncoder()\ntrain_df['label'] = label_encoder.fit_transform(train_df['individual_id'])\ntrain_df['path'] = DATA_DIR+train_df['image']\ntrain_df.head()","metadata":{"execution":{"iopub.status.busy":"2022-09-15T17:33:47.738273Z","iopub.execute_input":"2022-09-15T17:33:47.738643Z","iopub.status.idle":"2022-09-15T17:33:47.813572Z","shell.execute_reply.started":"2022-09-15T17:33:47.738610Z","shell.execute_reply":"2022-09-15T17:33:47.812610Z"},"trusted":true},"execution_count":20,"outputs":[{"execution_count":20,"output_type":"execute_result","data":{"text/plain":"                image             species individual_id  label  \\\n0  00021adfb725ed.jpg  melon_headed_whale  cadddb1636b9  12348   \n1  000562241d384d.jpg      humpback_whale  1a71fbb72250   1636   \n2  0007c33415ce37.jpg  false_killer_whale  60008f293a2b   5842   \n3  0007d9bca26a99.jpg  bottlenose_dolphin  4b00fe572063   4551   \n4  00087baf5cef7a.jpg      humpback_whale  8e5253662392   8721   \n\n                                                path  \n0  ../input/jpeg-happywhale-128x128/train_images-...  \n1  ../input/jpeg-happywhale-128x128/train_images-...  \n2  ../input/jpeg-happywhale-128x128/train_images-...  \n3  ../input/jpeg-happywhale-128x128/train_images-...  \n4  ../input/jpeg-happywhale-128x128/train_images-...  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>image</th>\n      <th>species</th>\n      <th>individual_id</th>\n      <th>label</th>\n      <th>path</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>00021adfb725ed.jpg</td>\n      <td>melon_headed_whale</td>\n      <td>cadddb1636b9</td>\n      <td>12348</td>\n      <td>../input/jpeg-happywhale-128x128/train_images-...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>000562241d384d.jpg</td>\n      <td>humpback_whale</td>\n      <td>1a71fbb72250</td>\n      <td>1636</td>\n      <td>../input/jpeg-happywhale-128x128/train_images-...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0007c33415ce37.jpg</td>\n      <td>false_killer_whale</td>\n      <td>60008f293a2b</td>\n      <td>5842</td>\n      <td>../input/jpeg-happywhale-128x128/train_images-...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0007d9bca26a99.jpg</td>\n      <td>bottlenose_dolphin</td>\n      <td>4b00fe572063</td>\n      <td>4551</td>\n      <td>../input/jpeg-happywhale-128x128/train_images-...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>00087baf5cef7a.jpg</td>\n      <td>humpback_whale</td>\n      <td>8e5253662392</td>\n      <td>8721</td>\n      <td>../input/jpeg-happywhale-128x128/train_images-...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"dataset = tf.data.Dataset.from_tensor_slices((train_df['path'], train_df['label']))\n\nfor image, label in dataset.take(1):\n    print(image)\n    print(label)","metadata":{"execution":{"iopub.status.busy":"2022-09-15T17:35:22.431272Z","iopub.execute_input":"2022-09-15T17:35:22.431718Z","iopub.status.idle":"2022-09-15T17:35:22.543699Z","shell.execute_reply.started":"2022-09-15T17:35:22.431682Z","shell.execute_reply":"2022-09-15T17:35:22.542523Z"},"trusted":true},"execution_count":22,"outputs":[{"name":"stdout","text":"tf.Tensor(b'../input/jpeg-happywhale-128x128/train_images-128-128/train_images-128-128/00021adfb725ed.jpg', shape=(), dtype=string)\ntf.Tensor(12348, shape=(), dtype=int64)\n","output_type":"stream"},{"name":"stderr","text":"2022-09-15 17:35:22.456134: I tensorflow/core/common_runtime/process_util.cc:146] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance.\n","output_type":"stream"}]},{"cell_type":"code","source":"def process_path(image_path, label):\n    img = tf.io.read_file(image_path)\n    img = tf.image.decode_jpeg(img, channels=3)\n    img = tf.image.convert_image_dtype(img, tf.float32)\n\n    return img, label\n\ndef preprocess(image, label):\n    input_image = tf.image.resize(image, (128, 128), method='nearest')\n\n    input_image = input_image / 255.\n\n    return input_image, label\n\nimage_ds = dataset.map(process_path, num_parallel_calls = AUTOTUNE)\nprocessed_image_ds = image_ds.map(preprocess, num_parallel_calls = AUTOTUNE)","metadata":{"execution":{"iopub.status.busy":"2022-09-15T17:37:06.274503Z","iopub.execute_input":"2022-09-15T17:37:06.274979Z","iopub.status.idle":"2022-09-15T17:37:06.340332Z","shell.execute_reply.started":"2022-09-15T17:37:06.274942Z","shell.execute_reply":"2022-09-15T17:37:06.339503Z"},"trusted":true},"execution_count":24,"outputs":[]},{"cell_type":"code","source":"for image, label in processed_image_ds.take(1):\n    print(image)\n    print(label)","metadata":{"execution":{"iopub.status.busy":"2022-09-15T17:37:28.203775Z","iopub.execute_input":"2022-09-15T17:37:28.204275Z","iopub.status.idle":"2022-09-15T17:37:28.339175Z","shell.execute_reply.started":"2022-09-15T17:37:28.204227Z","shell.execute_reply":"2022-09-15T17:37:28.338047Z"},"collapsed":true,"jupyter":{"outputs_hidden":true},"trusted":true},"execution_count":25,"outputs":[{"name":"stdout","text":"tf.Tensor(\n[[[0.00141484 0.00210688 0.00275279]\n  [0.00141484 0.00210688 0.00275279]\n  [0.00147636 0.00213764 0.00279892]\n  ...\n  [0.00089196 0.00141484 0.00215302]\n  [0.00083045 0.00135333 0.0020915 ]\n  [0.00096886 0.00149173 0.00222991]]\n\n [[0.00103037 0.00163014 0.00226067]\n  [0.00106113 0.0016609  0.00229143]\n  [0.00098424 0.00158401 0.00221453]\n  ...\n  [0.00083045 0.00138408 0.00212226]\n  [0.00089196 0.0014456  0.00218378]\n  [0.00076894 0.00132257 0.00206075]]\n\n [[0.00163014 0.00221453 0.0028143 ]\n  [0.00179931 0.0023837  0.00298347]\n  [0.0018762  0.00246059 0.00306036]\n  ...\n  [0.0009381  0.00150711 0.00219915]\n  [0.00099962 0.00156863 0.00226067]\n  [0.00103037 0.00159938 0.00227605]]\n\n ...\n\n [[0.00073818 0.00073818 0.00089196]\n  [0.00066128 0.00066128 0.00081507]\n  [0.00063053 0.00063053 0.00078431]\n  ...\n  [0.00076894 0.0007228  0.00083045]\n  [0.00078431 0.00073818 0.00084583]\n  [0.00078431 0.00073818 0.00084583]]\n\n [[0.00070742 0.00070742 0.00086121]\n  [0.00069204 0.00069204 0.00084583]\n  [0.00067666 0.00067666 0.00083045]\n  ...\n  [0.00078431 0.00073818 0.00084583]\n  [0.00078431 0.00070742 0.00081507]\n  [0.00076894 0.00069204 0.00079969]]\n\n [[0.00066128 0.00066128 0.00081507]\n  [0.00063053 0.00063053 0.00078431]\n  [0.00066128 0.00066128 0.00081507]\n  ...\n  [0.00078431 0.00073818 0.00084583]\n  [0.00079969 0.0007228  0.00083045]\n  [0.00079969 0.0007228  0.00083045]]], shape=(96, 128, 3), dtype=float32)\ntf.Tensor(12348, shape=(), dtype=int64)\n","output_type":"stream"},{"name":"stderr","text":"2022-09-15 17:37:28.221610: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:185] None of the MLIR Optimization Passes are enabled (registered 2)\n","output_type":"stream"}]},{"cell_type":"code","source":"dataset = processed_image_ds.shuffle(1024, reshuffle_each_iteration = True)\ndataset = dataset.prefetch(AUTOTUNE)","metadata":{"execution":{"iopub.status.busy":"2022-09-15T17:38:56.465560Z","iopub.execute_input":"2022-09-15T17:38:56.465990Z","iopub.status.idle":"2022-09-15T17:38:56.475930Z","shell.execute_reply.started":"2022-09-15T17:38:56.465952Z","shell.execute_reply":"2022-09-15T17:38:56.474730Z"},"trusted":true},"execution_count":26,"outputs":[]},{"cell_type":"code","source":"preprocess_input = tf.keras.applications.mobilenet_v2.preprocess_input","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"IMG_SIZE = (128, 128)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def whale_model(image_shape=IMG_SIZE):\n    ''' Define a tf.keras model for binary classification out of the MobileNetV2 model\n    Arguments:\n        image_shape -- Image width and height\n        data_augmentation -- data augmentation function\n    Returns:\n    Returns:\n        tf.keras.model\n    '''\n    \n    \n    input_shape = image_shape + (3,)\n    \n    base_model = tf.keras.applications.mobilenet_v2.MobileNetV2(\n    input_shape=input_shape,\n    include_top=False,\n    weights='imagenet'\n    )\n    \n    base_model.trainable = False\n    inputs = tf.keras.Input(input_shape)\n    \n    X = preprocess_input(inputs)\n    X = base_model(X, training=False)\n    \n    X = tfl.GlobalAveragePooling2D()(X)\n    X = tfl.Dropout(0.2)(X)\n    \n    prediction_layer = tfl.Dense(15587, activation='softmax')\n    \n    outputs = prediction_layer(X) \n    model = tf.keras.Model(inputs, outputs)\n    return model","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = whale_model(IMG_SIZE)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"base_learning_rate = 0.01\nmodel.compile(optimizer=tf.keras.optimizers.Adam(lr=base_learning_rate),\n              loss=tf.keras.metrics.TopKCategoricalAccuracy(k=5),\n              metrics=['accuracy'])","metadata":{},"execution_count":null,"outputs":[]}]}