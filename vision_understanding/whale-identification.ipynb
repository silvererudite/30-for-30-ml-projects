{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        os.path.join(dirname, filename)\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_kg_hide-output":true,"execution":{"iopub.status.busy":"2022-08-15T08:54:10.328086Z","iopub.execute_input":"2022-08-15T08:54:10.328497Z","iopub.status.idle":"2022-08-15T08:54:33.056472Z","shell.execute_reply.started":"2022-08-15T08:54:10.328467Z","shell.execute_reply":"2022-08-15T08:54:33.055577Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"import matplotlib.pyplot as plt\nimport seaborn as sns\nimport tensorflow as tf\nfrom tensorflow.keras.layers import Input, Dense, Conv2D, MaxPool2D, BatchNormalization, GlobalAveragePooling2D, Flatten, ZeroPadding2D, Rescaling\nfrom keras.preprocessing import image\nfrom keras.applications.imagenet_utils import preprocess_input","metadata":{"execution":{"iopub.status.busy":"2022-08-15T08:54:37.504039Z","iopub.execute_input":"2022-08-15T08:54:37.504464Z","iopub.status.idle":"2022-08-15T08:54:45.155785Z","shell.execute_reply.started":"2022-08-15T08:54:37.504431Z","shell.execute_reply":"2022-08-15T08:54:45.153958Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"train_df = pd.read_csv(\"/kaggle/input/humpback-whale-identification/train.csv\")","metadata":{"execution":{"iopub.status.busy":"2022-08-15T08:56:20.531289Z","iopub.execute_input":"2022-08-15T08:56:20.531758Z","iopub.status.idle":"2022-08-15T08:56:20.563200Z","shell.execute_reply.started":"2022-08-15T08:56:20.531725Z","shell.execute_reply":"2022-08-15T08:56:20.562287Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"train_df.shape","metadata":{"execution":{"iopub.status.busy":"2022-08-15T08:56:20.565172Z","iopub.execute_input":"2022-08-15T08:56:20.565671Z","iopub.status.idle":"2022-08-15T08:56:20.576024Z","shell.execute_reply.started":"2022-08-15T08:56:20.565615Z","shell.execute_reply":"2022-08-15T08:56:20.574457Z"},"trusted":true},"execution_count":6,"outputs":[{"execution_count":6,"output_type":"execute_result","data":{"text/plain":"(25361, 2)"},"metadata":{}}]},{"cell_type":"code","source":"d = dict(enumerate(train_df['Id'].astype('category').cat.categories))\n#d","metadata":{"execution":{"iopub.status.busy":"2022-08-15T08:56:20.577801Z","iopub.execute_input":"2022-08-15T08:56:20.578318Z","iopub.status.idle":"2022-08-15T08:56:20.608724Z","shell.execute_reply.started":"2022-08-15T08:56:20.578255Z","shell.execute_reply":"2022-08-15T08:56:20.607483Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"train_df['Id'] = train_df['Id'].astype('category').cat.codes","metadata":{"execution":{"iopub.status.busy":"2022-08-15T08:56:20.610827Z","iopub.execute_input":"2022-08-15T08:56:20.611443Z","iopub.status.idle":"2022-08-15T08:56:20.626627Z","shell.execute_reply.started":"2022-08-15T08:56:20.611403Z","shell.execute_reply":"2022-08-15T08:56:20.624944Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"test_df = pd.read_csv(\"/kaggle/input/humpback-whale-identification/sample_submission.csv\")","metadata":{"execution":{"iopub.status.busy":"2022-08-15T08:56:20.628160Z","iopub.execute_input":"2022-08-15T08:56:20.628807Z","iopub.status.idle":"2022-08-15T08:56:20.656172Z","shell.execute_reply.started":"2022-08-15T08:56:20.628770Z","shell.execute_reply":"2022-08-15T08:56:20.655078Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"train_df.head()","metadata":{"execution":{"iopub.status.busy":"2022-08-15T08:56:20.658009Z","iopub.execute_input":"2022-08-15T08:56:20.658684Z","iopub.status.idle":"2022-08-15T08:56:20.674757Z","shell.execute_reply.started":"2022-08-15T08:56:20.658644Z","shell.execute_reply":"2022-08-15T08:56:20.673226Z"},"trusted":true},"execution_count":10,"outputs":[{"execution_count":10,"output_type":"execute_result","data":{"text/plain":"           Image    Id\n0  0000e88ab.jpg  4786\n1  0001f9222.jpg  3808\n2  00029d126.jpg   662\n3  00050a15a.jpg     0\n4  0005c1ef8.jpg     0","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Image</th>\n      <th>Id</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0000e88ab.jpg</td>\n      <td>4786</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0001f9222.jpg</td>\n      <td>3808</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>00029d126.jpg</td>\n      <td>662</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>00050a15a.jpg</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0005c1ef8.jpg</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"INP_SIZE      = (512, 512) \nTARGET_SIZE   = (150, 150) \nINTERPOLATION = \"bilinear\"\nN_CLASSES = 5005\n\nNUM_FOLDS  = 5\nBATCH_SIZE = 128\nSEED       = 42\n\nDATA_DIR  = '../input/humpback-whale-identification/'\nTRAIN_DIR = DATA_DIR + 'train/'\nTEST_DIR  = DATA_DIR + 'test/'","metadata":{"execution":{"iopub.status.busy":"2022-08-15T08:56:20.675809Z","iopub.execute_input":"2022-08-15T08:56:20.676143Z","iopub.status.idle":"2022-08-15T08:56:20.682131Z","shell.execute_reply.started":"2022-08-15T08:56:20.676113Z","shell.execute_reply":"2022-08-15T08:56:20.681175Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"# SetAutoTune\nAUTOTUNE = tf.data.AUTOTUNE \n#https://www.kaggle.com/ipythonx/tf-keras-learning-to-resize-image-for-vit-model/notebook\ndef build_augmenter(is_labelled):\n    def augment(img):\n        img = tf.image.random_flip_left_right(img)\n        img = tf.image.random_flip_up_down(img)\n        img = tf.image.random_saturation(img, 0.65, 1.05)\n        img = tf.image.random_brightness(img, 0.05)\n        img = tf.image.random_contrast(img, 0.75, 1.05)\n        img = tf.image.random_hue(img, 0.05)\n        return img\n    \n    def augment_with_labels(img, label):\n        return augment(img), label\n    return augment_with_labels if is_labelled else augment\n\ndef build_decoder(is_labelled, size):\n    def decode(path):\n        file_bytes = tf.io.read_file(path)\n        img = tf.image.decode_jpeg(file_bytes, channels = 1)\n        img = tf.image.resize(img, (size[0], size[1]))\n        return img\n    \n    def decode_with_labels(path, label):\n        label = tf.cast(label, tf.int32)\n        return decode(path),label\n    \n    return decode_with_labels if is_labelled else decode\n\ndef create_dataset(df, \n                   batch_size  = 64, \n                   is_labelled = False, \n                   augment     = False, \n                   repeat      = False, \n                   shuffle     = False,\n                   size        = TARGET_SIZE):\n    decode_fn    = build_decoder(is_labelled, size)\n    augmenter_fn = build_augmenter(is_labelled)\n    \n    # Create Dataset\n    if is_labelled:\n        dataset = tf.data.Dataset.from_tensor_slices((df['Image'].values, df['Id'].values))\n    else:\n        dataset = tf.data.Dataset.from_tensor_slices((df['Image'].values))\n        \n    dataset = dataset.map(decode_fn, num_parallel_calls = AUTOTUNE)\n    dataset = dataset.map(augmenter_fn, num_parallel_calls = AUTOTUNE) if augment else dataset\n    dataset = dataset.repeat(batch_size) if repeat else dataset\n    dataset = dataset.shuffle(1024, reshuffle_each_iteration = True) if shuffle else dataset\n    dataset = dataset.batch(batch_size)\n    dataset = dataset.cache().prefetch(buffer_size=AUTOTUNE)\n    return dataset","metadata":{"execution":{"iopub.status.busy":"2022-08-15T08:56:20.683760Z","iopub.execute_input":"2022-08-15T08:56:20.684569Z","iopub.status.idle":"2022-08-15T08:56:20.699991Z","shell.execute_reply.started":"2022-08-15T08:56:20.684532Z","shell.execute_reply":"2022-08-15T08:56:20.698659Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"train_df['Image'] = train_df['Image'].apply(lambda x: f'{TRAIN_DIR}{x}')","metadata":{"execution":{"iopub.status.busy":"2022-08-15T08:56:20.719186Z","iopub.execute_input":"2022-08-15T08:56:20.719954Z","iopub.status.idle":"2022-08-15T08:56:20.735816Z","shell.execute_reply.started":"2022-08-15T08:56:20.719908Z","shell.execute_reply":"2022-08-15T08:56:20.734775Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"train_ds = create_dataset(train_df, batch_size = BATCH_SIZE, is_labelled = True, repeat = True)","metadata":{"execution":{"iopub.status.busy":"2022-08-15T08:56:20.738368Z","iopub.execute_input":"2022-08-15T08:56:20.739537Z","iopub.status.idle":"2022-08-15T08:56:20.943007Z","shell.execute_reply.started":"2022-08-15T08:56:20.739487Z","shell.execute_reply":"2022-08-15T08:56:20.940817Z"},"trusted":true},"execution_count":14,"outputs":[{"name":"stderr","text":"2022-08-15 08:56:20.763958: I tensorflow/core/common_runtime/process_util.cc:146] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance.\n","output_type":"stream"}]},{"cell_type":"code","source":"for image_batch, labels_batch in train_ds:\n  print(image_batch.shape)\n  print(labels_batch.shape)\n  break","metadata":{"execution":{"iopub.status.busy":"2022-08-15T08:56:20.944159Z","iopub.execute_input":"2022-08-15T08:56:20.944525Z","iopub.status.idle":"2022-08-15T08:56:21.547651Z","shell.execute_reply.started":"2022-08-15T08:56:20.944493Z","shell.execute_reply":"2022-08-15T08:56:21.546688Z"},"trusted":true},"execution_count":15,"outputs":[{"name":"stderr","text":"2022-08-15 08:56:20.982024: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:185] None of the MLIR Optimization Passes are enabled (registered 2)\n","output_type":"stream"},{"name":"stdout","text":"(128, 150, 150, 1)\n(128,)\n","output_type":"stream"},{"name":"stderr","text":"2022-08-15 08:56:21.543435: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n","output_type":"stream"}]},{"cell_type":"code","source":"test_df['Image'] = test_df['Image'].apply(lambda x: f'{TEST_DIR}{x}')\ntest_ds = create_dataset(test_df, batch_size = BATCH_SIZE)","metadata":{"execution":{"iopub.status.busy":"2022-08-15T08:56:21.548692Z","iopub.execute_input":"2022-08-15T08:56:21.549022Z","iopub.status.idle":"2022-08-15T08:56:21.572886Z","shell.execute_reply.started":"2022-08-15T08:56:21.548994Z","shell.execute_reply":"2022-08-15T08:56:21.571606Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"for image_batch in test_ds:\n  print(image_batch.shape)\n  break","metadata":{"execution":{"iopub.status.busy":"2022-08-15T08:56:21.576737Z","iopub.execute_input":"2022-08-15T08:56:21.577559Z","iopub.status.idle":"2022-08-15T08:56:22.007003Z","shell.execute_reply.started":"2022-08-15T08:56:21.577507Z","shell.execute_reply":"2022-08-15T08:56:22.006131Z"},"trusted":true},"execution_count":17,"outputs":[{"name":"stdout","text":"(128, 150, 150, 1)\n","output_type":"stream"},{"name":"stderr","text":"2022-08-15 08:56:21.993059: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n","output_type":"stream"}]},{"cell_type":"code","source":"model = tf.keras.Sequential([\n    Rescaling(1./255, input_shape=(150, 150,1)),\n    Conv2D(32, (3,3),1,padding='same', activation='relu'),\n    BatchNormalization(axis=1, momentum = 0.99, epsilon=0.001),\n    MaxPool2D((2,2)),\n    \n    Conv2D(64, (3,3),1,padding='same', activation='relu'),\n    BatchNormalization(axis=1, momentum = 0.99, epsilon=0.001),\n    MaxPool2D((2,2)),\n    \n    GlobalAveragePooling2D(),\n    BatchNormalization(axis=1, momentum = 0.99, epsilon=0.001),\n    Dense(N_CLASSES, activation='sigmoid')\n])","metadata":{"execution":{"iopub.status.busy":"2022-08-15T09:11:32.105108Z","iopub.execute_input":"2022-08-15T09:11:32.105552Z","iopub.status.idle":"2022-08-15T09:11:32.221682Z","shell.execute_reply.started":"2022-08-15T09:11:32.105517Z","shell.execute_reply":"2022-08-15T09:11:32.220789Z"},"trusted":true},"execution_count":35,"outputs":[]},{"cell_type":"code","source":"model.compile(\n loss='sparse_categorical_crossentropy', metrics=[tf.keras.metrics.TopKCategoricalAccuracy(k=5)], optimizer=\"adam\")","metadata":{"execution":{"iopub.status.busy":"2022-08-15T09:11:32.223723Z","iopub.execute_input":"2022-08-15T09:11:32.224463Z","iopub.status.idle":"2022-08-15T09:11:32.243796Z","shell.execute_reply.started":"2022-08-15T09:11:32.224417Z","shell.execute_reply":"2022-08-15T09:11:32.242563Z"},"trusted":true},"execution_count":36,"outputs":[]},{"cell_type":"code","source":"model.summary()","metadata":{"execution":{"iopub.status.busy":"2022-08-15T09:11:32.245447Z","iopub.execute_input":"2022-08-15T09:11:32.246128Z","iopub.status.idle":"2022-08-15T09:11:32.255912Z","shell.execute_reply.started":"2022-08-15T09:11:32.246077Z","shell.execute_reply":"2022-08-15T09:11:32.254647Z"},"trusted":true},"execution_count":37,"outputs":[{"name":"stdout","text":"Model: \"sequential_3\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\nrescaling_3 (Rescaling)      (None, 150, 150, 1)       0         \n_________________________________________________________________\nconv2d_6 (Conv2D)            (None, 150, 150, 32)      320       \n_________________________________________________________________\nbatch_normalization_9 (Batch (None, 150, 150, 32)      600       \n_________________________________________________________________\nmax_pooling2d_6 (MaxPooling2 (None, 75, 75, 32)        0         \n_________________________________________________________________\nconv2d_7 (Conv2D)            (None, 75, 75, 64)        18496     \n_________________________________________________________________\nbatch_normalization_10 (Batc (None, 75, 75, 64)        300       \n_________________________________________________________________\nmax_pooling2d_7 (MaxPooling2 (None, 37, 37, 64)        0         \n_________________________________________________________________\nglobal_average_pooling2d_1 ( (None, 64)                0         \n_________________________________________________________________\nbatch_normalization_11 (Batc (None, 64)                256       \n_________________________________________________________________\ndense_5 (Dense)              (None, 5005)              325325    \n=================================================================\nTotal params: 345,297\nTrainable params: 344,719\nNon-trainable params: 578\n_________________________________________________________________\n","output_type":"stream"}]},{"cell_type":"code","source":"checkpoint_path = \"/kaggle/working/mymodel/training_2/cp-{epoch:04d}.ckpt\"\ncheckpoint_dir = os.path.dirname(checkpoint_path)\ncallbacks = [\n    tf.keras.callbacks.ModelCheckpoint(\n        # Path where to save the model\n        # The two parameters below mean that we will overwrite\n        # the current checkpoint if and only if\n        # the `val_loss` score has improved.\n        # The saved model name will include the current epoch.\n        filepath= checkpoint_path,\n        verbose=1,\n        save_weights_only=True\n    )\n]","metadata":{"execution":{"iopub.status.busy":"2022-08-15T09:11:32.258810Z","iopub.execute_input":"2022-08-15T09:11:32.259927Z","iopub.status.idle":"2022-08-15T09:11:32.273590Z","shell.execute_reply.started":"2022-08-15T09:11:32.259875Z","shell.execute_reply":"2022-08-15T09:11:32.272563Z"},"trusted":true},"execution_count":38,"outputs":[]},{"cell_type":"code","source":"model.save_weights(checkpoint_path.format(epoch=0))","metadata":{"execution":{"iopub.status.busy":"2022-08-15T09:11:32.275218Z","iopub.execute_input":"2022-08-15T09:11:32.276491Z","iopub.status.idle":"2022-08-15T09:11:32.305260Z","shell.execute_reply.started":"2022-08-15T09:11:32.276445Z","shell.execute_reply":"2022-08-15T09:11:32.303810Z"},"trusted":true},"execution_count":39,"outputs":[]},{"cell_type":"code","source":"history = model.fit(\n  train_ds,\n  epochs=10,\n  steps_per_epoch = 64,\n  callbacks=callbacks\n)","metadata":{"execution":{"iopub.status.busy":"2022-08-15T09:12:48.491514Z","iopub.execute_input":"2022-08-15T09:12:48.491925Z","iopub.status.idle":"2022-08-15T09:16:38.244250Z","shell.execute_reply.started":"2022-08-15T09:12:48.491883Z","shell.execute_reply":"2022-08-15T09:16:38.241521Z"},"collapsed":true,"jupyter":{"outputs_hidden":true},"trusted":true},"execution_count":41,"outputs":[{"name":"stdout","text":"Epoch 1/10\n64/64 [==============================] - 118s 2s/step - loss: 8.0103 - top_k_categorical_accuracy: 0.5317\n\nEpoch 00001: saving model to /kaggle/working/mymodel/training_2/cp-0001.ckpt\nEpoch 2/10\n59/64 [==========================>...] - ETA: 9s - loss: 7.4824 - top_k_categorical_accuracy: 0.6373 ","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_17/2539514937.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m   \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m   \u001b[0msteps_per_epoch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m64\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m   \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m )\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1182\u001b[0m                 _r=1):\n\u001b[1;32m   1183\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1184\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1185\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1186\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    883\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    884\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 885\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    886\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    887\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    915\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    916\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 917\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    918\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    919\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   3038\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m   3039\u001b[0m     return graph_function._call_flat(\n\u001b[0;32m-> 3040\u001b[0;31m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m   3041\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3042\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1962\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1963\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1964\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1965\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1966\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    594\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    595\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 596\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    597\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    598\u001b[0m           outputs = execute.execute_with_cancellation(\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 60\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "],"ename":"KeyboardInterrupt","evalue":"","output_type":"error"}]},{"cell_type":"code","source":"os.listdir(checkpoint_dir)","metadata":{"execution":{"iopub.status.busy":"2022-08-15T09:16:38.246045Z","iopub.status.idle":"2022-08-15T09:16:38.246692Z","shell.execute_reply.started":"2022-08-15T09:16:38.246388Z","shell.execute_reply":"2022-08-15T09:16:38.246418Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"latest = tf.train.latest_checkpoint(checkpoint_dir)","metadata":{"execution":{"iopub.status.busy":"2022-08-15T09:16:38.248488Z","iopub.status.idle":"2022-08-15T09:16:38.249109Z","shell.execute_reply.started":"2022-08-15T09:16:38.248813Z","shell.execute_reply":"2022-08-15T09:16:38.248839Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.load_weights(latest)","metadata":{"execution":{"iopub.status.busy":"2022-08-15T09:16:38.251728Z","iopub.status.idle":"2022-08-15T09:16:38.252359Z","shell.execute_reply.started":"2022-08-15T09:16:38.252021Z","shell.execute_reply":"2022-08-15T09:16:38.252066Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"preds = model.predict(test_ds)","metadata":{"execution":{"iopub.status.busy":"2022-08-15T09:16:38.254275Z","iopub.status.idle":"2022-08-15T09:16:38.254899Z","shell.execute_reply.started":"2022-08-15T09:16:38.254601Z","shell.execute_reply":"2022-08-15T09:16:38.254632Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"len(preds)","metadata":{"execution":{"iopub.status.busy":"2022-08-15T09:16:38.256435Z","iopub.status.idle":"2022-08-15T09:16:38.256998Z","shell.execute_reply.started":"2022-08-15T09:16:38.256721Z","shell.execute_reply":"2022-08-15T09:16:38.256747Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"preds.shape","metadata":{"execution":{"iopub.status.busy":"2022-08-15T09:16:38.259984Z","iopub.status.idle":"2022-08-15T09:16:38.260705Z","shell.execute_reply.started":"2022-08-15T09:16:38.260464Z","shell.execute_reply":"2022-08-15T09:16:38.260489Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission_df = pd.read_csv(\"/kaggle/input/humpback-whale-identification/sample_submission.csv\")\n","metadata":{"execution":{"iopub.status.busy":"2022-08-15T09:16:38.262256Z","iopub.status.idle":"2022-08-15T09:16:38.262709Z","shell.execute_reply.started":"2022-08-15T09:16:38.262487Z","shell.execute_reply":"2022-08-15T09:16:38.262518Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for i, pred in enumerate(preds):\n    arr = pred.argsort()[-5:][::-1]\n    submission_df.loc[i, 'Id'] = \" \".join(np.vectorize(d.get)(arr))","metadata":{"execution":{"iopub.status.busy":"2022-08-15T09:16:38.264450Z","iopub.status.idle":"2022-08-15T09:16:38.264833Z","shell.execute_reply.started":"2022-08-15T09:16:38.264655Z","shell.execute_reply":"2022-08-15T09:16:38.264672Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission_df.to_csv('submission.csv', index = False)\nprint(submission_df.shape)","metadata":{"execution":{"iopub.status.busy":"2022-08-15T09:16:38.266186Z","iopub.status.idle":"2022-08-15T09:16:38.266603Z","shell.execute_reply.started":"2022-08-15T09:16:38.266409Z","shell.execute_reply":"2022-08-15T09:16:38.266430Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}